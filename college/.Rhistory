which.min(rf_cv$error.cv)
#Remove 5 variables based on Importance of Variables
sort(importance(rf_1)[,1])
summary(m9)
#Remove 4 variables based on Importance of Variables
sort(importance(rf_1)[,1])
reg_formula <- as.formula(Apps ~ Accept  + Enroll + F.Undergrad + Top10perc +
Room.Board  + Grad.Rate + Top25perc + Outstate +
Expend + Private + perc.alumni + Terminal + PhD +
P.Undergrad )
rf_2 <- randomForest(reg_formula, data = train, mtry = 4, ntree = 500, nodesize = 5)
rf_2
#mtry
#     for regression = p/3
rf_1
reg_formula
class(reg_formula)
#mtry
floor(sqrt(14))
rf_2 <- randomForest(reg_formula, data = train, mtry = 3, ntree = 500, nodesize = 5)
rf_2
pred_rf
pred_rf - test
abs(pred_rf - test)
test
pred_rf
pred_rf
pred_rf  <- predict(rf_2, test)
pred_rf
View(test)
pred_rf
abs(pred_rf)
abs_err_rf <- abs(pred_rf)
models_comp <- rbind(models_comp, "RandomForest" = c(mean(abs_err_rf),
median(abs_err_rf),
sd(abs_err_rf),
IQR(abs_err_rf),
range(abs_err_rf)))
View(models_comp)
models_comp
models_comp <- data.frame("Mean of AbsErrors"   = mean(abs_err_lm),
"Median of AbsErrors" = median(abs_err_lm),
"SD of AbsErrors"  = sd(abs_err_lm),
"IQR of AbsErrors" = IQR(abs_err_lm),
"Min of AbsErrors" = min(abs_err_lm),
"Max of AbsErrors" = max(abs_err_lm),
row.names = 'LM_t-test')
View(models_comp)
View(models_comp)
models_comp <- data.frame("Mean of AbsErrors"   = mean(abs_err_lm),
"Median of AbsErrors" = median(abs_err_lm),
"SD of AbsErrors"  = sd(abs_err_lm),
"IQR of AbsErrors" = IQR(abs_err_lm),
"Min of AbsErrors" = min(abs_err_lm),
"Max of AbsErrors" = max(abs_err_lm),
row.names = 'LM_t-test')
View(models_comp)
plot(test$Salary, pred_rf, main = 'RandomForest',
xlim = c(0, 2000), ylim = c(0, 2000),
xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)
pred_rf
plot(test$Apps, pred_rf, main = 'RandomForest',
xlim = c(0, 2000), ylim = c(0, 2000),
xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)
models_comp <- data.frame("Mean of AbsErrors"   = mean(abs_err_lm),
"Median of AbsErrors" = median(abs_err_lm),
"SD of AbsErrors"  = sd(abs_err_lm),
"IQR of AbsErrors" = IQR(abs_err_lm),
"Min of AbsErrors" = min(abs_err_lm),
"Max of AbsErrors" = max(abs_err_lm),
row.names = 'LM_t-test')
#Absolute error mean, median, sd, max, min-------
abs_err_rf <- abs(pred_rf - test$Apps)
models_comp <- data.frame("Mean of AbsErrors"   = mean(abs_err_lm),
"Median of AbsErrors" = median(abs_err_lm),
"SD of AbsErrors"  = sd(abs_err_lm),
"IQR of AbsErrors" = IQR(abs_err_lm),
"Min of AbsErrors" = min(abs_err_lm),
"Max of AbsErrors" = max(abs_err_lm),
row.names = 'LM_t-test')
View(models_comp)
abs_err_rf
mean(abs_err_lm
)
abs_err_rf <- abs(pred_rf - test$Apps)
abs_err_rf
models_comp <- data.frame("Mean of AbsErrors"   = mean(abs_err_lm),
"Median of AbsErrors" = median(abs_err_lm),
"SD of AbsErrors"  = sd(abs_err_lm),
"IQR of AbsErrors" = IQR(abs_err_lm),
"Min of AbsErrors" = min(abs_err_lm),
"Max of AbsErrors" = max(abs_err_lm),
row.names = 'LM_t-test')
abs_err_rf <- abs(pred_rf - test$Apps)
models_comp <- data.frame("Mean of AbsErrors"   = mean(abs_err_lm),
"Median of AbsErrors" = median(abs_err_lm),
"SD of AbsErrors"  = sd(abs_err_lm),
"IQR of AbsErrors" = IQR(abs_err_lm),
"Min of AbsErrors" = min(abs_err_lm),
"Max of AbsErrors" = max(abs_err_lm),
row.names = 'LM_t-test')
View(models_comp)
mean(abs_err_lm)
abs_err_rf <- abs(pred_rf)
mean(abs_err_lm)
View(cor_table)
pred_rf
view(pred_rf)
view(pred_rf)
predict(rf_2, test)
pred_rf  <- predict(rf_2, test)
view(pred_rf)
pred_rf
abs(pred_rf)
abs_err_rf <- abs(pred_rf)
data.frame("Mean of AbsErrors"   = mean(abs_err_lm),
"Median of AbsErrors" = median(abs_err_lm),
"SD of AbsErrors"  = sd(abs_err_lm),
"IQR of AbsErrors" = IQR(abs_err_lm),
"Min of AbsErrors" = min(abs_err_lm),
"Max of AbsErrors" = max(abs_err_lm),
row.names = 'LM_t-test')
abs_err_rf <- abs(pred_rf)
models_comp <- data.frame("Mean of AbsErrors"   = mean(abs_err_rf),
"Median of AbsErrors" = median(abs_err_rf),
"SD of AbsErrors"  = sd(abs_err_rf),
"IQR of AbsErrors" = IQR(abs_err_rf),
"Min of AbsErrors" = min(abs_err_rf),
"Max of AbsErrors" = max(abs_err_rf),
row.names = 'LM_t-test')
View(models_comp)
rf_2
install.packages("glmnet")
x <- model.matrix(Apps ~ . , data = train)[, -1] #remove intercept
y <- train$Apps
View(x)
lassoreg_1 <- glmnet(x, y, alpha = 1, lambda = lambda_grid, standardize = TRUE, intercept = TRUE)
library("glmnet")
# LASSO ----
lassoreg_1 <- glmnet(x, y, alpha = 1, lambda = lambda_grid, standardize = TRUE, intercept = TRUE)
x <- model.matrix(Apps ~ . , data = train)[, -1] #remove intercept
y <- train$Apps
lambda_grid <- 10 ^ seq(5, -2, length = 100) # we can change more grid and each time focus more to find better
lambda_grid
# LASSO ----
lassoreg_1 <- glmnet(x, y, alpha = 1, lambda = lambda_grid, standardize = TRUE, intercept = TRUE)
dim(coef(lassoreg_1))
#Plot Reg. Coefficients vs. Log Lambda
plot(lassoreg_1, xvar = "lambda")
#Retrieve Coefficients
lassoreg_1$lambda [90]
#Retrieve Coefficients
lassoreg_1$lambda [90]
coef(lassoreg_1)[, 90]
#Retrieve Coefficients
lassoreg_1$lambda [20]
coef(lassoreg_1)[, 20]
#Cross validation to choose the best model
lasso_cv    <- cv.glmnet(x, y, alpha = 1, lambda = lambda_grid, nfolds = 10)
#The mean cross-validated error
lasso_cv$cvm
#Estimate of standard error of cvm.
lasso_cv$cvsd
#value of lambda that gives minimum cvm
lasso_cv$lambda.min
lassoreg_2 <- glmnet(x, y, alpha = 1, lambda = lasso_cv$lambda.min, standardize = TRUE, intercept = TRUE)
coef(lassoreg_2)
pred_lassoreg <- predict(lassoreg_2, s = lasso_cv$lambda.min, newx = x_test)
pred_lassoreg
predict(lassoreg_2, s = lasso_cv$lambda.min, newx = x_test)
pred_lassoreg <- predict(lassoreg_2, s = lasso_cv$lambda.min, newx = x)
pred_lassoreg
abs_err_lassoreg <- abs(pred_lassoreg)
models_comp <- rbind(models_comp, "LASSOReg" = c(mean(abs_err_lassoreg),
median(abs_err_lassoreg),
sd(abs_err_lassoreg),
IQR(abs_err_lassoreg),
range(abs_err_lassoreg)))
View(models_comp)
coef(lassoreg_2)
setwd("D:\PhD\Data Science\dataScienceHWProject\college")
getwd()
data<- read.csv("college.csv", header = TRUE)
colnames(data)
#Remove College.Name
unique(data$College.Name)
#Remove College.Name
unique(data$College.Name)
length(unique(data$College.Name))
data <- data[,-1]
data
unique(data$Private)
length(unique(data$Private))
#customer_type------------
summary(data$Grad.Rate)
for (i in 2:18){
print(colnames(data[i]))
print(summary(data[, i]))
}
# Categorical data
data$Private <- factor(data$Private)
summary(data)
#distribution
par(mfrow = c(3, 3))  # 4 rows and 4 columns
#distribution
par(mfrow = c(3, 3))  # 4 rows and 4 columns
#Continuous variables distribution
for (i in 3:18) {
hist(data[, i], xlab = "",  probability = T, breaks = 15,
main = paste("Histogram of", names(data)[i]))
lines(density(data[,i]), col = "red")
}
for (i in 3:18) {
qqnorm(data[,i], main = paste("QQ plot of", names(data)[i]), pch = 20)
qqline(data[,i], col = "red")
}
par(mfrow = c(2, 2))  # 2 rows and 2 columns
for (i in 3:18) {
plot(data[,i], data$Apps, xlab = "", main = paste("Apps vs.", names(data)[i]))
}
par(mfrow = c(1,1))
boxplot(data$Apps, main = "Number of applications received")
# categorical
table(data$Private)
tukey_ul <- quantile(data$Apps, probs = 0.75) + 1.5 * IQR(data$Apps)
tukey_ul
sum(data$Apps > tukey_ul)
sum(data$Apps > tukey_ul)/nrow(data) * 100
corrplot(cor_table)
cor_table <- round(cor(data[, c(2: 18)]), 2)
View(cor_table)
corrplot(cor_table)
View(cor_table)
corrplot(cor_table)
library("corrplot") #Visualization of Correlation Matrix
library("car")
library("corrplot")
library("glmnet")
library("randomForest")
corrplot(cor_table)
par(mfrow = c(1,1))
corrplot(cor_table)
par(mar = c(2, 2, 2, 2))
par(mfrow = c(3, 3))  # 4 rows and 4 columns
for (i in c(3:18)) {
plot(data[, i], data$Apps, xlab = "", main = paste("Apps vs.", names(data)[i]))
}
par(mfrow = c(1, 1), mar = c(4.5, 4.5, 4.5, 4.5))
tapply(data$Apps, data$Private, mean)
#Categorical variables
table(data$Private)     # we want to check Categorical data are not distributed
m0 <-lm(Apps ~ Private  , data = train)
summary(m0)
m10 <-lm(Apps ~ Private + Accept + Enroll + Top10perc + Top25perc + F.Undergrad +
P.Undergrad + Outstate + Room.Board + PhD + Expend + Grad.Rate , data = train)
summary(m10)
m10
class(m10)
plot(m10)
plot(m0)
par(mfrow = c(1, 1), mar = c(4.5, 4.5, 4.5, 4.5))
plot(m0)
m0 <-lm(Apps ~ Private  , data = train)
summary(m0)
m1 <-lm(Apps ~ Accept, data = train)
summary(m1)
plot(m1)
plot(m2)
plot(m3)
plot(m5)
plot(m6)
plot(m7)
plot(m8)
plot(m9)
m10 <-lm(Apps ~ Private + Accept + Enroll + Top10perc + Top25perc + F.Undergrad +
P.Undergrad + Outstate + Room.Board + PhD + Expend + Grad.Rate , data = train)
summary(m10)
m10
plot(m10)
car :: vif(m10)
box_results <- boxcox(Apps ~ ., data = train, lambda = seq(-5, 5, 0.1))
install.packages("mice")
# Model 2 data manipulate -->
## Box-Cox Transformation
box_results <- boxcox(Apps ~ ., data = train, lambda = seq(-5, 5, 0.1))
library("moments")  #Moments, skewness, kurtosis and related tests
library("MASS")     #Box-Cox Transformations for Linear Models
boxcox(Apps ~ ., data = train, lambda = seq(-5, 5, 0.1))
box_results <- boxcox(Apps ~ ., data = train, lambda = seq(-5, 5, 0.1))
box_results <- data.frame(box_results$x, box_results$y)
box_results
lambda <- box_results[which(box_results$box_results.y == max(box_results$box_results.y)), 1]
lambda
((train$Apps) ^ lambda - 1) /lambda
train$newApps <- ((train$Apps) ^ lambda - 1) /lambda
train
View(train)
View(data)
data<- read.csv("college.csv", header = TRUE)
colnames(data)
class(data)
dim(data)
head(data)
tail(data, 2)
View(head(data,20))
str(data)
summary(data)
unique(data$College.Name)
length(unique(data$College.Name))
data <- data[,-1]
# Categorical data
data$Private <- factor(data$Private)
summary(data)
for (i in 3:18) {
qqnorm(data[,i], main = paste("QQ plot of", names(data)[i]), pch = 20)
qqline(data[,i], col = "red")
}
tapply(data$Apps, data$Private, mean)
set.seed(1234)
train_cases <- sample(1:nrow(data), nrow(data) * 0.7)  # we have enough data to study 70-30
train <- data[train_cases,]
test  <- data[- train_cases,]
dim(train)
summary(train)
dim(test)
summary(test)
m10 <-lm(Apps ~ . = train)
m10 <-lm(Apps ~ . ,data= train)
summary(m10)
m10
plot(m10)
box_results <- boxcox(Apps ~ ., data = train, lambda = seq(-5, 5, 0.1))
box_results <- data.frame(box_results$x, box_results$y)
lambda <- box_results[which(box_results$box_results.y == max(box_results$box_results.y)), 1]
lambda
train$newApps <- ((train$Apps) ^ lambda - 1) /lambda
m10New <-lm(Apps ~ .-newApps, data = train)
m10New
summary(m10New)
summary(m10)
car :: vif(m10New)
plot(m10New)
train
subset (train, select = -newApps)
train <- subset (train, select = -newApps)
train
(train)
dim(train)
bestsub_1 <- regsubsets(Apps ~ . , nvmax = 18, data = train, method = "exhaustive")
summary(bestsub_1)
install.packages("leaps")
library(leaps)
bestsub_1 <- regsubsets(Apps ~ . , nvmax = 18, data = train, method = "exhaustive")
summary(bestsub_1)
summary(bestsub_1)$rsq
plot(summary(bestsub_1)$adjr2,
type = "b",
xlab = "# of Variables",
ylab = "AdjR2",
xaxt = 'n',
xlim = c(1, 18)); grid()
axis(1, at = 1: 18, labels = 1: 18)
points(which.max(summary(bestsub_1)$adjr2),
summary(bestsub_1)$adjr2[which.max(summary(bestsub_1)$adjr2)],
col = "red", cex = 2, pch = 20)
plot(summary(bestsub_1)$cp,
type = "b",
xlab = "# of Variables",
ylab = "Cp",
xaxt = 'n',
xlim = c(1, 19)); grid()
axis(1, at = 1: 19, labels = 1: 19)
points(which.min(summary(bestsub_1)$cp),
summary(bestsub_1)$cp[which.min(summary(bestsub_1)$cp)],
col = "red", cex = 2, pch = 20)
#Plot BIC
plot(summary(bestsub_1)$bic,
type = "b",
xlab = "# of Variables",
ylab = "BIC",
xaxt = 'n',
xlim = c(1, 19)); grid()
axis(1, at = 1: 19, labels = 1: 19)
points(which.min(summary(bestsub_1)$bic),
summary(bestsub_1)$bic[which.min(summary(bestsub_1)$bic)],
col = "red", cex = 2, pch = 20)
coef(bestsub_1, 17)
coef(bestsub_1, 11)
coef(bestsub_1, 18)
coef(bestsub_1, 17)
plot(summary(bestsub_1)$bic,
type = "b",
xlab = "# of Variables",
ylab = "BIC",
xaxt = 'n',
xlim = c(1, 19)); grid()
axis(1, at = 1: 19, labels = 1: 19)
points(which.min(summary(bestsub_1)$bic),
summary(bestsub_1)$bic[which.min(summary(bestsub_1)$bic)],
col = "red", cex = 2, pch = 20)
summary(bestsub_1)$rsq
summary(bestsub_1)
bestsub_1
View(x)
summary(bestsub_1)[,9]
summary(bestsub_1)[,]
summary(bestsub_1[,6])
summary(bestsub_1)
bestsub2 <- lm(  ~ Accept +Top10perc + Top25perc + PrivateYes + Enroll +
Outstate + Room.Board + PhD  + Expend , data = train)
summary(bestsub2)
bestsub2 <- lm(  ~ Accept +Top10perc + Top25perc + PrivateYes + Enroll +
Outstate + Room.Board + PhD  + Expend , data = train)
bestsub2 <- lm(  ~ Accept +Top10perc + Top25perc + Private + Enroll +
Outstate + Room.Board + PhD  + Expend , data = train)
bestsub2 <- lm(Apps  ~ Accept +Top10perc + Top25perc + Private + Enroll +
Outstate + Room.Board + PhD  + Expend , data = train)
summary(bestsub2)
bestsub2_BIC <- lm(Apps  ~ Accept +Top10perc + Top25perc + Private + Enroll +
Outstate + Room.Board + PhD  + Expend , data = train)
summary(bestsub2_BIC)
plot(summary(bestsub_1)$cp,
type = "b",
xlab = "# of Variables",
ylab = "Cp",
xaxt = 'n',
xlim = c(1, 19)); grid()
axis(1, at = 1: 19, labels = 1: 19)
points(which.min(summary(bestsub_1)$cp),
summary(bestsub_1)$cp[which.min(summary(bestsub_1)$cp)],
col = "red", cex = 2, pch = 20)
plot(summary(bestsub_1)$adjr2,
type = "b",
xlab = "# of Variables",
ylab = "AdjR2",
xaxt = 'n',
xlim = c(1, 18)); grid()
axis(1, at = 1: 18, labels = 1: 18)
points(which.max(summary(bestsub_1)$adjr2),
summary(bestsub_1)$adjr2[which.max(summary(bestsub_1)$adjr2)],
col = "red", cex = 2, pch = 20)
bestsub2_BIC <- lm(Apps  ~ Accept +Top10perc + Top25perc + Private + Enroll +
Outstate + Room.Board + PhD  + Expend , data = train)
summary(bestsub2_BIC)
bestsub2_Cp <- lm(Apps  ~ Accept +Top10perc + Top25perc + Private + Enroll +
Outstate + Room.Board + PhD  + Expend + Grad.Rate
F.Undergrad + P.Undergrad, data = train)
summary(bestsub2_Cp)
bestsub2_Cp <- lm(Apps  ~ Accept +Top10perc + Top25perc + Private + Enroll +
Outstate + Room.Board + PhD  + Expend + Grad.Rate +
F.Undergrad + P.Undergrad, data = train)
summary(bestsub2_Cp)
pred_bestsub  <- predict(bestsub2_Cp, test)    #we predict the log salary so we should use exp to find the real amount of salary
pred_bestsub
abs_err_bestsub <- abs(pred_bestsub)
models_comp <- rbind(models_comp, 'BestSubset_AdjR2' = c(mean(abs_err_bestsub),
median(abs_err_bestsub),
sd(abs_err_bestsub),
IQR(abs_err_bestsub),
range(abs_err_bestsub)))
View(models_comp)
plot(test$Apps, pred_bestsub, main = 'BestSubset_BIC',
xlim = c(0, 2000), ylim = c(0, 2000),
xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)
models_comp <- rbind(models_comp, 'BestSubset_BIC' = c(mean(abs_err_bestsub),
median(abs_err_bestsub),
sd(abs_err_bestsub),
IQR(abs_err_bestsub),
range(abs_err_bestsub)))
View(models_comp)
pred_bestsub
test$Apps
abs_err_bestsub <- abs(pred_bestsub -test$Apps )
models_comp <- rbind(models_comp, 'BestSubset_BIC' = c(mean(abs_err_bestsub),
median(abs_err_bestsub),
sd(abs_err_bestsub),
IQR(abs_err_bestsub),
range(abs_err_bestsub)))
View(models_comp)
abs_err_lassoreg <- abs(pred_lassoreg - test$Apps)
models_comp <- rbind(models_comp, "LASSOReg" = c(mean(abs_err_lassoreg),
median(abs_err_lassoreg),
sd(abs_err_lassoreg),
IQR(abs_err_lassoreg),
range(abs_err_lassoreg)))
View(models_comp)
lassoreg_2 <- glmnet(x, y, alpha = 1, lambda = lasso_cv$lambda.min, standardize = TRUE, intercept = TRUE)
coef(lassoreg_2)
pred_lassoreg <- predict(lassoreg_2, s = lasso_cv$lambda.min, newx = x)
pred_lassoreg
abs_err_lassoreg <- abs(pred_lassoreg - test$Apps)
models_comp <- rbind(models_comp, "LASSOReg" = c(mean(abs_err_lassoreg),
median(abs_err_lassoreg),
sd(abs_err_lassoreg),
IQR(abs_err_lassoreg),
range(abs_err_lassoreg)))
View(models_comp)
pred_rf
abs_err_rf <- abs(pred_rf - test$Apps)
models_comp <- data.frame("Mean of AbsErrors"   = mean(abs_err_rf),
"Median of AbsErrors" = median(abs_err_rf),
"SD of AbsErrors"  = sd(abs_err_rf),
"IQR of AbsErrors" = IQR(abs_err_rf),
"Min of AbsErrors" = min(abs_err_rf),
"Max of AbsErrors" = max(abs_err_rf),
row.names = 'LM_t-test')
View(models_comp)
clear
cls
